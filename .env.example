# LLM Provider Configuration
LLM_PROVIDER=ollama  # "openai" or "ollama"

# OpenAI Configuration (Optional - only needed if LLM_PROVIDER=openai)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Tavily Search Configuration
TAVILY_API_KEY=your_tavily_api_key_here

# Embedding Configuration
EMBEDDING_PROVIDER=ollama  # "openai" or "ollama"
EMBEDDING_MODEL=nomic-embed-text
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Application Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_PORT=8501

# ChromaDB Configuration
CHROMA_PERSIST_DIR=./vectordb
CHROMA_COLLECTION_NAME=internal_knowledge

# Model Configuration
OPENAI_MODEL=gpt-4o
EMBEDDING_MODEL=text-embedding-3-small
TEMPERATURE=0.7

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
